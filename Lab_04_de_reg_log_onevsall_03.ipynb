{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MAR123EREE/Laboratorio_02/blob/main/Lab_04_de_reg_log_onevsall_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clyp4NcQycWP",
        "outputId": "61b2bf53-fa32-4a0d-a4d2-3ca0993565ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "20Q29kX8SxgJ"
      },
      "outputs": [],
      "source": [
        "# utilizado para la manipulación de directorios y rutas\n",
        "import os\n",
        "\n",
        "# Cálculo científico y vectorial para python\n",
        "import numpy as np\n",
        "\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Modulo de optimizacion en scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# modulo para cargar archivos en formato MATLAB\n",
        "# from scipy.io import loadmat\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hhRjL2ptSxgK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# La entrada es de 784 elemento contando con x0\n",
        "input_layer_size  = 784\n",
        "# 10 etiquetas, de 1 a 10 (tomar en cuenta que se asigna \"0\" a la etiqueta 10), en este caso son 10 etiquetas\n",
        "num_labels = 10\n",
        "#  datos de entrenamiento almacenados en los arreglos X, y\n",
        "data = pd.read_csv('/content/drive/MyDrive/Data_sets/Lab_04/mnist_train.csv', delimiter=',')\n",
        "X = data.iloc[:, :1]\n",
        "#todo\n",
        "y = data.iloc[:, 0]\n",
        "m = y.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aw2yVc8ESxgL",
        "outputId": "ad0e1858-2303-43fa-8109-c70f9760a0a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label    5\n",
            "Name: 0, dtype: int64\n",
            "0        5\n",
            "1        0\n",
            "2        4\n",
            "3        1\n",
            "4        9\n",
            "        ..\n",
            "59995    8\n",
            "59996    3\n",
            "59997    5\n",
            "59998    6\n",
            "59999    8\n",
            "Name: label, Length: 60000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(X.iloc[0,:])\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion train_test_split, que recibe X y y, test_size es el tamaño de prueba\n",
        "#Aqui depende de cuanta parte del cod debe ser de prueba y entenamiento\n",
        "!pip install scikit-learn # install scikit-learn if you haven't already\n",
        "from sklearn.model_selection import train_test_split # import the train_test_split function\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd8qsb3hVf8v",
        "outputId": "9388095e-7004-43ab-9eb2-5f60631d15a5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimiendo la división del dataset para entrenamiento y prueba"
      ],
      "metadata": {
        "id": "QJT3Jy2EV_1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Datos entrenamiento> \")\n",
        "print(X_train)\n",
        "print('-'*40)\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXjnA3LhVmqt",
        "outputId": "c494a3ae-4ffb-417f-e89e-38ec1a980d7e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos entrenamiento> \n",
            "          label\n",
            "20379 -0.157111\n",
            "53032 -0.157111\n",
            "27005  0.881222\n",
            "30510  1.227333\n",
            "508   -1.195444\n",
            "...         ...\n",
            "55169 -1.195444\n",
            "49861 -0.157111\n",
            "27063 -1.195444\n",
            "8366   1.227333\n",
            "17530  1.227333\n",
            "\n",
            "[48000 rows x 1 columns]\n",
            "----------------------------------------\n",
            "20379    4\n",
            "53032    4\n",
            "27005    7\n",
            "30510    8\n",
            "508      1\n",
            "        ..\n",
            "55169    1\n",
            "49861    4\n",
            "27063    1\n",
            "8366     8\n",
            "17530    8\n",
            "Name: label, Length: 48000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Datos prueba> \")\n",
        "print(X_test)\n",
        "print('-'*40)\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxMl_NoXVq5L",
        "outputId": "91b381cd-3458-43e0-8d6f-6b10c0532f6f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos prueba> \n",
            "          label\n",
            "41382 -0.849333\n",
            "20883  0.881222\n",
            "13621  0.535111\n",
            "41823 -1.195444\n",
            "33839  1.227333\n",
            "...         ...\n",
            "34502 -1.541555\n",
            "730    0.881222\n",
            "17814  0.535111\n",
            "37767 -0.157111\n",
            "39655 -0.849333\n",
            "\n",
            "[12000 rows x 1 columns]\n",
            "----------------------------------------\n",
            "41382    2\n",
            "20883    7\n",
            "13621    6\n",
            "41823    1\n",
            "33839    8\n",
            "        ..\n",
            "34502    0\n",
            "730      7\n",
            "17814    6\n",
            "37767    4\n",
            "39655    2\n",
            "Name: label, Length: 12000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizacion de datos, desviacion estandar y es un código que se apróxima\n",
        "def  featureNormalize(X):\n",
        "    X_norm = X_train.copy()\n",
        "    mu = np.zeros(X_train.shape[1])\n",
        "    sigma = np.zeros(X_train.shape[1])\n",
        "\n",
        "    mu = np.mean(X_train, axis = 0)\n",
        "    sigma = np.std(X_train, axis = 0)\n",
        "    X_norm = (X_train - mu) / sigma\n",
        "\n",
        "    return X_norm, mu, sigma"
      ],
      "metadata": {
        "id": "HWF5C5Jt8wNb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X_train)"
      ],
      "metadata": {
        "id": "f4W6d-ya1ABV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_norm.iloc[0,:]) # Usando .iloc for integrar-based indexando en pandas\n",
        "print(y_train)"
      ],
      "metadata": {
        "id": "_lk8TeZPt5_S",
        "outputId": "d2318835-df11-41c5-bb87-24a144ee3d9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label   -0.84255\n",
            "Name: 41382, dtype: float64\n",
            "20379    4\n",
            "53032    4\n",
            "27005    7\n",
            "30510    8\n",
            "508      1\n",
            "        ..\n",
            "55169    1\n",
            "49861    4\n",
            "27063    1\n",
            "8366     8\n",
            "17530    8\n",
            "Name: label, Length: 48000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n",
        "m, n = X.shape\n",
        "X = X_norm"
      ],
      "metadata": {
        "id": "r9e6MRrW1G22"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "B5marXeKSxgM"
      },
      "outputs": [],
      "source": [
        "# Selecciona aleatoriamente 100 puntos de datos para mostrar\n",
        "rand_indices = np.random.choice(m, 100, replace=False)\n",
        "sel = X.iloc[rand_indices, :]\n",
        "#displayData(sel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0sB9Kyi8SxgN"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    \"\"\"\n",
        "    Calcula la sigmoide de z.\n",
        "    \"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba la implementacion de la funcion sigmoid\n",
        "z = 0\n",
        "g = sigmoid(z)\n",
        "\n",
        "print('g(', z, ') = ', g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU97nlHSW5wF",
        "outputId": "99843761-ed25-4fb5-8522-29d4d46b19f2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g( 0 ) =  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "w5S0OOswSxgN"
      },
      "outputs": [],
      "source": [
        "#Lamnda se usa y es un valor pequeño que va multiplicar ciertos valores\n",
        "def lrCostFunction(theta, X_train, y_train, lambda_):\n",
        "    \"\"\"\n",
        "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y\n",
        "    el gradiente del costo w.r.t. a los parámetros.\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    theta : array_like\n",
        "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas\n",
        "        incluida la intercepcion\n",
        "\n",
        "    X : array_like\n",
        "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de\n",
        "        caracteristicas (incluida la intercepcion).\n",
        "\n",
        "    y : array_like\n",
        "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
        "\n",
        "    lambda_ : float\n",
        "        Parametro de regularización.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    J : float\n",
        "        El valor calculado para la funcion de costo regularizada.\n",
        "\n",
        "    grad : array_like\n",
        "        Un vector de la forma (shape) (n, ) que es el gradiente de la\n",
        "        función de costo con respecto a theta, en los valores actuales de theta..\n",
        "    \"\"\"\n",
        "#     alpha = 0.003\n",
        "#     theta = theta.copy()\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y_train.size\n",
        "\n",
        "    # convierte las etiquetas a valores enteros si son boleanos\n",
        "    if y_train.dtype == bool:\n",
        "        y_train = y_train.astype(int)\n",
        "#esta grad le estamos pasando la cantidad de titas\n",
        "    J = 0\n",
        "    grad = np.zeros(theta.shape)\n",
        "\n",
        "    h = sigmoid(X_train.dot(theta.T))\n",
        "\n",
        "    temp = theta\n",
        "    temp[0] = 0\n",
        "\n",
        "#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))   el de + es el regulador, eso evitsrs que hay un sobre ajuste\n",
        "    J = (1 / m) * np.sum(-y_train.dot(np.log(h)) - (1 - y_train).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
        "\n",
        "    # Remplazar X con X_train\n",
        "    grad = (1 / m) * (h - y_train).dot(X_train)\n",
        "#     theta = theta - (alpha / m) * (h - y).dot(X)\n",
        "    grad = grad + (lambda_ / m) * temp\n",
        "\n",
        "    return J, grad\n",
        "#    return J, theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlk-Z2p-SxgN"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "### 1.4 Clasificacion One-vs-all\n",
        "En esta parte del ejercicio, se implementará la clasificación de uno contra todos mediante el entrenamiento de múltiples clasificadores de regresión logística regularizados, uno para cada una de las clases $K$ en nuestro conjunto de datos. En el conjunto de datos de dígitos escritos a mano, $K = 10$, pero su código debería funcionar para cualquier valor de $K$.\n",
        "\n",
        "El argumento `y` de esta función es un vector de etiquetas de 0 a 9. Al entrenar el clasificador para la clase $k \\in \\{0, ..., K-1 \\} $, querrá un vector K-dimensional de etiquetas $y$, donde $y_j \\ in 0, 1$ indica si la instancia de entrenamiento $j ^ {th}$ pertenece a la clase $k$ $(y_j = 1)$, o si pertenece a una clase diferente $(y_j = 0)$.\n",
        "\n",
        "Además, se utiliza `optimize.minimize` de scipy para este ejercicio.\n",
        "<a id=\"oneVsAll\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "V0rOw5qhSxgN"
      },
      "outputs": [],
      "source": [
        "#one vs all esta esta creando una matriz 10*784 porque hay 10 clasificaciones y valores de tetas\n",
        "def oneVsAll(X_train, y_train, num_labels, lambda_):\n",
        "    \"\"\"\n",
        "    Trains num_labels logistic regression classifiers and returns\n",
        "    each of these classifiers in a matrix all_theta, where the i-th\n",
        "    row of all_theta corresponds to the classifier for label i.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like\n",
        "        The input dataset of shape (m x n). m is the number of\n",
        "        data points, and n is the number of features. Note that we\n",
        "        do not assume that the intercept term (or bias) is in X, however\n",
        "        we provide the code below to add the bias term to X.\n",
        "\n",
        "    y : array_like\n",
        "        The data labels. A vector of shape (m, ).\n",
        "\n",
        "    num_labels : int\n",
        "        Number of possible labels.\n",
        "\n",
        "    lambda_ : float\n",
        "        The logistic regularization parameter.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        (ie. `numlabels`) and n is number of features without the bias.\n",
        "    \"\"\"\n",
        "    # algunas variables utiles\n",
        "    m, n = X_train.shape\n",
        "\n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "\n",
        "    # Agrega unos a la matriz X\n",
        "    X_train = np.concatenate([np.ones((m, 1)), X_train], axis=1)\n",
        "\n",
        "    for c in np.arange(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "        options = {'maxiter': 50}\n",
        "        # en x estan todos los valores de titas que estaba buscando\n",
        "        res = optimize.minimize(lrCostFunction,\n",
        "                                initial_theta,\n",
        "                                (X_train, (y_train == c), lambda_),\n",
        "                                jac=True,\n",
        "                                method='CG',\n",
        "                                options=options)\n",
        "\n",
        "        all_theta[c] = res.x\n",
        "\n",
        "    return all_theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "w6JbsLLMSxgO",
        "outputId": "07876a96-24cc-4482-b5d6-172eba278566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ],
      "source": [
        "lambda_ = 0.1\n",
        "all_theta = oneVsAll(X_train, y_train, num_labels, lambda_)\n",
        "#me esta devolviendo el tamaño\n",
        "print(all_theta.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1EfKaiEgtcw",
        "outputId": "ab8d86c3-4434-4299-c34e-d6634bfdb5d0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-49.29873705 -35.96675143]\n",
            " [ -3.79931268  -2.48756209]\n",
            " [ -2.71547303  -1.17492017]\n",
            " [ -2.31186819  -0.60258196]\n",
            " [ -2.2291234   -0.17750648]\n",
            " [ -2.32821283   0.20698051]\n",
            " [ -2.3659796    0.63072216]\n",
            " [ -2.68503595   1.21240655]\n",
            " [ -3.95651236   2.40767473]\n",
            " [-49.61780977  35.44274498]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "PjFoFe1bSxgO"
      },
      "outputs": [],
      "source": [
        "def predictOneVsAll(all_theta, X_train):\n",
        "    \"\"\"\n",
        "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
        "    Tenga en cuenta que X contiene los ejemplos en filas.\n",
        "    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase.\n",
        "    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1]\n",
        "    predice clases 0, 2, 0, 1 para 4 ejemplos).\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        and n is number of features without the bias.\n",
        "\n",
        "    X : array_like\n",
        "        Data points to predict their labels. This is a matrix of shape\n",
        "        (m x n) where m is number of data points to predict, and n is number\n",
        "        of features without the bias term. Note we add the bias term for X in\n",
        "        this function.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    p : array_like\n",
        "        The predictions for each data point in X. This is a vector of shape (m, ).\n",
        "    \"\"\"\n",
        "  #numero de valores de m\n",
        "    m = X_train.shape[0];\n",
        "    #numero de etiquetas num lebel,\n",
        "    num_labels = all_theta.shape[0]\n",
        "    #estamos crando p para la \"y\" predicha,\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    # Add ones to the X data matrix\n",
        "    X_train = np.concatenate([np.ones((m, 1)), X_train], axis=1)\n",
        "    #es el q va devolver el que tiene mayor probabilidad me refiero argmax\n",
        "    p = np.argmax(sigmoid(X_train.dot(all_theta.T)), axis = 1)\n",
        "\n",
        "    return p"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo3aawvsSxgO"
      },
      "source": [
        "Una vez que haya terminado, se llama a la función `predictOneVsAll` usando el valor aprendido de $\\theta$. Debería apreciarse que la precisión del conjunto de entrenamiento es de aproximadamente 81.15%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mE7v5cglSxgO",
        "outputId": "b4bd951b-c87c-4d15-cea3-6ec09a4f9717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 1)\n",
            "Precision del conjuto de entrenamiento: 81.15%\n",
            "(140, 1)\n",
            "(140, 2)\n",
            "[6 6 6 3 4 7 7 1 1 6 3 1 4 0 7 4 8 1 3 1 8 0 1 1 0 1 1 6 4 7 8 7 7 4 4 8 3\n",
            " 4 6 0 6 6 8 0 4 4 1 9 3 6 6 1 6 9 3 1 4 4 3 8 4 8 4 6 7 7 6 1 6 7 8 8 6 1\n",
            " 7 8 4 3 9 0 3 1 4 6 9 6 8 7 7 0 7 4 1 8 8 1 7 7 1 6 1 6 6 1 1 1 1 3 4 1 4\n",
            " 8 6 6 4 7 1 8 1 4 6 8 1 1 6 1 9 1 0 6 4 3 0 4 0 6 7 1 6 6]\n",
            "45753    5\n",
            "13047    6\n",
            "6004     5\n",
            "49729    3\n",
            "39703    4\n",
            "        ..\n",
            "44262    5\n",
            "41928    7\n",
            "20461    1\n",
            "42509    5\n",
            "44293    5\n",
            "Name: label, Length: 140, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "#si la prediccion es igual a \"y\"\n",
        "pred = predictOneVsAll(all_theta, X_train)\n",
        "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y_train) * 100))\n",
        "XPrueba = X_train.iloc[10:150, :].copy()  # Colocar .iloc para integrar la locación\n",
        "print(XPrueba.shape)\n",
        "#p = np.zeros(1)\n",
        "XPrueba = np.concatenate([np.ones((140, 1)), XPrueba], axis=1)\n",
        "print(XPrueba.shape)\n",
        "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
        "print(p)\n",
        "\n",
        "# displayData(X[1002:1003, :])\n",
        "print(y_train[10:150])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La otra parte del dataset de prueba"
      ],
      "metadata": {
        "id": "_fx2espDbUs_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "7WaT8luNSxgO"
      },
      "outputs": [],
      "source": [
        "#Normalizacion de datos, con la desviacion estandar y es un código que se apróxima\n",
        "def  featureNormalize(X):\n",
        "    X_norm = X_test.copy()\n",
        "    mu = np.zeros(X_test.shape[1])\n",
        "    sigma = np.zeros(X_test.shape[1])\n",
        "\n",
        "    mu = np.mean(X_test, axis = 0)\n",
        "    sigma = np.std(X_test, axis = 0)\n",
        "    X_norm = (X_test - mu) / sigma\n",
        "\n",
        "    return X_norm, mu, sigma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X_test)"
      ],
      "metadata": {
        "id": "0-cSj_YbbqCi"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_norm.iloc[0,:]) # Usando .iloc for integrar-based indexando en pandas\n",
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5r9SJFvbzs_",
        "outputId": "ac6a5623-ec6b-4b8d-9aa9-d22d6aff2cfa"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label   -0.84255\n",
            "Name: 41382, dtype: float64\n",
            "41382    2\n",
            "20883    7\n",
            "13621    6\n",
            "41823    1\n",
            "33839    8\n",
            "        ..\n",
            "34502    0\n",
            "730      7\n",
            "17814    6\n",
            "37767    4\n",
            "39655    2\n",
            "Name: label, Length: 12000, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n",
        "m, n = X.shape\n",
        "X = X_norm"
      ],
      "metadata": {
        "id": "xy3U9kxMcCR3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecciona aleatoriamente 100 puntos de datos para mostrar\n",
        "rand_indices = np.random.choice(X.shape[0], 100, replace=False) # Use the current shape of X\n",
        "sel = X.iloc[rand_indices, :]\n",
        "#displayData(sel)"
      ],
      "metadata": {
        "id": "8uFev0L4cF3u"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lamnda se usa y es un valor pequeño que va multiplicar ciertos valores\n",
        "def lrCostFunction(theta, X_test, y_test, lambda_):\n",
        "    \"\"\"\n",
        "    Calcula el costo de usar theta como parámetro para la regresión logística regularizada y\n",
        "    el gradiente del costo w.r.t. a los parámetros.\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    theta : array_like\n",
        "        Parametro theta de la regresion logistica. Vector de la forma(shape) (n, ). n es el numero de caracteristicas\n",
        "        incluida la intercepcion\n",
        "\n",
        "    X : array_like\n",
        "        Dataset con la forma(shape) (m x n). m es el numero de ejemplos, y n es el numero de\n",
        "        caracteristicas (incluida la intercepcion).\n",
        "\n",
        "    y : array_like\n",
        "        El conjunto de etiquetas. Un vector con la forma (shape) (m, ). m es el numero de ejemplos\n",
        "\n",
        "    lambda_ : float\n",
        "        Parametro de regularización.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    J : float\n",
        "        El valor calculado para la funcion de costo regularizada.\n",
        "\n",
        "    grad : array_like\n",
        "        Un vector de la forma (shape) (n, ) que es el gradiente de la\n",
        "        función de costo con respecto a theta, en los valores actuales de theta..\n",
        "    \"\"\"\n",
        "#     alpha = 0.003\n",
        "#     theta = theta.copy()\n",
        "    # Inicializa algunos valores utiles\n",
        "    m = y_test.size\n",
        "\n",
        "    # convierte las etiquetas a valores enteros si son boleanos\n",
        "    if y_test.dtype == bool:\n",
        "        y_test = y_test.astype(int)\n",
        "#esta grad le estamos pasando la cantidad de titas\n",
        "    J = 0\n",
        "    grad = np.zeros(theta.shape)\n",
        "\n",
        "    h = sigmoid(X_test.dot(theta.T))\n",
        "\n",
        "    temp = theta\n",
        "    temp[0] = 0\n",
        "\n",
        "#     J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))   el de + es el regulador, eso evitsrs que hay un sobre ajuste\n",
        "    J = (1 / m) * np.sum(-y_test.dot(np.log(h)) - (1 - y_test).dot(np.log(1 - h))) + (lambda_ / (2 * m)) * np.sum(np.square(temp))\n",
        "\n",
        "    # Remplazar X con X_train\n",
        "    grad = (1 / m) * (h - y_test).dot(X_test)\n",
        "#     theta = theta - (alpha / m) * (h - y).dot(X)\n",
        "    grad = grad + (lambda_ / m) * temp\n",
        "\n",
        "    return J, grad\n",
        "#    return J, theta"
      ],
      "metadata": {
        "id": "sepgXkq_cd82"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one vs all esta esta creando una matriz 10*784 porque hay 10 clasificaciones y valores de tetas\n",
        "def oneVsAll(X_test, y_test, num_labels, lambda_):\n",
        "    \"\"\"\n",
        "    Trains num_labels logistic regression classifiers and returns\n",
        "    each of these classifiers in a matrix all_theta, where the i-th\n",
        "    row of all_theta corresponds to the classifier for label i.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array_like\n",
        "        The input dataset of shape (m x n). m is the number of\n",
        "        data points, and n is the number of features. Note that we\n",
        "        do not assume that the intercept term (or bias) is in X, however\n",
        "        we provide the code below to add the bias term to X.\n",
        "\n",
        "    y : array_like\n",
        "        The data labels. A vector of shape (m, ).\n",
        "\n",
        "    num_labels : int\n",
        "        Number of possible labels.\n",
        "\n",
        "    lambda_ : float\n",
        "        The logistic regularization parameter.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        (ie. `numlabels`) and n is number of features without the bias.\n",
        "    \"\"\"\n",
        "    # algunas variables utiles\n",
        "    m, n = X_test.shape\n",
        "\n",
        "    all_theta = np.zeros((num_labels, n + 1))\n",
        "\n",
        "    # Agrega unos a la matriz X\n",
        "    X_test = np.concatenate([np.ones((m, 1)), X_test], axis=1)\n",
        "\n",
        "    for c in np.arange(num_labels):\n",
        "        initial_theta = np.zeros(n + 1)\n",
        "        options = {'maxiter': 50}\n",
        "        # en x estan todos los valores de titas que estaba buscando\n",
        "        res = optimize.minimize(lrCostFunction,\n",
        "                                initial_theta,\n",
        "                                (X_test, (y_test == c), lambda_),\n",
        "                                jac=True,\n",
        "                                method='CG',\n",
        "                                options=options)\n",
        "\n",
        "        all_theta[c] = res.x\n",
        "\n",
        "    return all_theta"
      ],
      "metadata": {
        "id": "TCb5iDutcxjv"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambda_ = 0.1\n",
        "all_theta = oneVsAll(X_test, y_test, num_labels, lambda_)\n",
        "#me esta devolviendo el tamaño\n",
        "print(all_theta.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trebeTknkTCj",
        "outputId": "ae6e8b07-dd74-4297-ae83-7ccc79e1b69e"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UocbGUfknRE",
        "outputId": "bc676431-32f1-4c79-cfab-9808b5b66081"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-39.57575105 -28.87821592]\n",
            " [ -3.80648878  -2.47130502]\n",
            " [ -2.6555693   -1.17282916]\n",
            " [ -2.31370631  -0.59220682]\n",
            " [ -2.28015288  -0.16685606]\n",
            " [ -2.32320914   0.21713813]\n",
            " [ -2.37955239   0.64130976]\n",
            " [ -2.65819818   1.23407476]\n",
            " [ -3.98792567   2.45047157]\n",
            " [-39.98908385  28.55228736]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predictOneVsAll(all_theta, X_test):\n",
        "    \"\"\"\n",
        "    Devuelve un vector de predicciones para cada ejemplo en la matriz X.\n",
        "    Tenga en cuenta que X contiene los ejemplos en filas.\n",
        "    all_theta es una matriz donde la i-ésima fila es un vector theta de regresión logística entrenada para la i-ésima clase.\n",
        "    Debe establecer p en un vector de valores de 0..K-1 (por ejemplo, p = [0, 2, 0, 1]\n",
        "    predice clases 0, 2, 0, 1 para 4 ejemplos).\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    all_theta : array_like\n",
        "        The trained parameters for logistic regression for each class.\n",
        "        This is a matrix of shape (K x n+1) where K is number of classes\n",
        "        and n is number of features without the bias.\n",
        "\n",
        "    X : array_like\n",
        "        Data points to predict their labels. This is a matrix of shape\n",
        "        (m x n) where m is number of data points to predict, and n is number\n",
        "        of features without the bias term. Note we add the bias term for X in\n",
        "        this function.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    p : array_like\n",
        "        The predictions for each data point in X. This is a vector of shape (m, ).\n",
        "    \"\"\"\n",
        "  #numero de valores de m\n",
        "    m = X_test.shape[0];\n",
        "    #numero de etiquetas num lebel,\n",
        "    num_labels = all_theta.shape[0]\n",
        "    #estamos crando p para la \"y\" predicha,\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    # Add ones to the X data matrix\n",
        "    X_test = np.concatenate([np.ones((m, 1)), X_test], axis=1)\n",
        "    #es el q va devolver el que tiene mayor probabilidad me refiero argmax\n",
        "    p = np.argmax(sigmoid(X_test.dot(all_theta.T)), axis = 1)\n",
        "\n",
        "    return p"
      ],
      "metadata": {
        "id": "1JCWcM5pkzHf"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)\n",
        "#si la prediccion es igual a \"y\"\n",
        "pred = predictOneVsAll(all_theta, X_test)\n",
        "print('Precision del conjuto de entrenamiento: {:.2f}%'.format(np.mean(pred == y_test) * 100))\n",
        "XPrueba = X_test.iloc[10:150, :].copy()  # Colocar .iloc para integrar la locación\n",
        "print(XPrueba.shape)\n",
        "#p = np.zeros(1)\n",
        "XPrueba = np.concatenate([np.ones((140, 1)), XPrueba], axis=1)\n",
        "print(XPrueba.shape)\n",
        "p = np.argmax(sigmoid(XPrueba.dot(all_theta.T)), axis = 1)\n",
        "print(p)\n",
        "\n",
        "# displayData(X[1002:1003, :])\n",
        "print(y_test[10:150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRRWWhJglBrS",
        "outputId": "a2c7b660-0501-4dd2-c91a-eae0730d8e8a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12000, 1)\n",
            "Precision del conjuto de entrenamiento: 71.78%\n",
            "(140, 1)\n",
            "(140, 2)\n",
            "[2 9 9 8 2 7 0 7 8 0 9 1 0 3 1 2 2 3 3 8 0 0 1 2 6 2 6 1 0 7 7 2 3 2 3 7 6\n",
            " 3 7 8 6 3 6 3 9 7 7 3 2 6 9 3 2 9 0 3 2 7 3 7 3 7 8 0 2 7 7 1 9 6 0 3 8 7\n",
            " 3 1 9 7 1 7 7 2 7 3 2 2 9 7 3 2 3 7 0 7 6 2 2 7 3 1 9 1 9 1 9 9 0 7 3 6 6\n",
            " 9 9 1 7 8 3 9 2 1 7 8 2 6 1 2 3 9 6 2 7 9 3 6 3 0 7 8 1 9]\n",
            "32523    2\n",
            "30698    9\n",
            "16588    9\n",
            "35365    8\n",
            "55220    2\n",
            "        ..\n",
            "56       0\n",
            "35648    7\n",
            "50342    8\n",
            "42339    1\n",
            "23919    9\n",
            "Name: label, Length: 140, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay una diferencia de la precisión del conjubto de entrenamiento; entre train(81.15%) y test(71.78%)"
      ],
      "metadata": {
        "id": "_vVrs_GclfP_"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}